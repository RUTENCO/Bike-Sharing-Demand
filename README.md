## ğŸš² Bike Sharing Demand - Kaggle Challenge

### ğŸ“Œ DescripciÃ³n del reto
Los sistemas de bicicletas compartidas permiten alquilar bicicletas por periodos cortos a travÃ©s de estaciones automÃ¡ticas distribuidas por la ciudad. En este desafÃ­o, se pide predecir cuÃ¡ntas bicicletas serÃ¡n alquiladas en un determinado momento, utilizando informaciÃ³n sobre el clima, la fecha y otros factores.

El dataset contiene informaciÃ³n horaria de dos aÃ±os, y el entrenamiento se realiza con los primeros 19 dÃ­as de cada mes, mientras que las predicciones deben hacerse desde el dÃ­a 20 en adelante.

La mÃ©trica de evaluaciÃ³n utilizada es el Root Mean Squared Logarithmic Error (RMSLE).

---

### ğŸ“¦ Objetivo

Predecir el nÃºmero total de alquileres (`count`) por hora, utilizando Ãºnicamente la informaciÃ³n disponible **previa al momento de la predicciÃ³n**.

---

### ğŸ“ Estructura del Dataset

| Columna      | DescripciÃ³n |
|--------------|-------------|
| `datetime`   | Fecha y hora del registro |
| `season`     | Temporada del aÃ±o (1: primavera, 2: verano, 3: otoÃ±o, 4: invierno) |
| `holiday`    | Si el dÃ­a fue festivo |
| `workingday` | Si fue un dÃ­a laboral (ni fin de semana ni festivo) |
| `weather`    | CondiciÃ³n climÃ¡tica categorizada (de 1 a 4) |
| `temp`       | Temperatura en Â°C |
| `atemp`      | SensaciÃ³n tÃ©rmica en Â°C |
| `humidity`   | Humedad relativa |
| `windspeed`  | Velocidad del viento |
| `casual`     | Alquileres por usuarios no registrados |
| `registered` | Alquileres por usuarios registrados |
| `count`      | Total de alquileres por hora (objetivo de predicciÃ³n) |

---

### ğŸ§ª EvaluaciÃ³n

Las predicciones se evalÃºan con la mÃ©trica **RMSLE (Root Mean Squared Logarithmic Error)**, que penaliza mÃ¡s las predicciones por debajo del valor real y es adecuada para distribuciones sesgadas con valores extremos.

![Captura de la formula RMSLE](RMSLE.png)

Donde:
- \( p_i \): valor predicho
- \( a_i \): valor real
- \( n \): nÃºmero de muestras

---

### ğŸ”— Fuente del dataset

El conjunto de datos fue provisto por **Hadi Fanaee Tork** y es parte del repositorio de aprendizaje automÃ¡tico de la UCI. Se utiliza principalmente para fines educativos y de prÃ¡ctica en modelado predictivo.

---

### ğŸ§  Fase 1 - ExploraciÃ³n y Modelado con Notebook

#### ğŸ”§ Requisitos previos

Puedes ejecutar este proyecto directamente en Google Colab. Para ello:

Descarga el notebook **(EDA)_Bike_Sharing_Demand.ipynb**.

Sube el archivo a tu Google Drive.

Ãbrelo desde Colab: haz clic derecho sobre el archivo en Drive â†’ Abrir con â†’ Google Colab.

**Nota:**  
La soluciÃ³n presentada en este notebook se basa en trabajos previos de la comunidad de Kaggle.  
En particular, se han tomado ideas y enfoques de los siguientes notebooks:

- ğŸ“˜ [**biketest** por ensari](https://www.kaggle.com/code/ensari/biketest)
- ğŸ“— [**Bike Sharing Demand** por jaeraklim](https://www.kaggle.com/code/jaeraklim/bike-sharing-demand)

Estas soluciones sirvieron como guÃ­a para realizar la ingenierÃ­a de caracterÃ­sticas, entrenar modelos como Random Forest, XGBoost y LightGBM, y estructurar la lÃ³gica de predicciÃ³n para el envÃ­o de resultados a la competencia.


ğŸ“ **Pasos para ejecutar el notebook**

1. Ãšnete al reto en Kaggle y acepta las reglas para habilitar la descarga de los datos:

   ğŸ‘‰ https://www.kaggle.com/competitions/bike-sharing-demand/data

2. AsegÃºrate de tener los siguientes archivos descargados desde Kaggle:

   - `train.csv`
   - `test.csv`

3. Existen dos formas de acceder a estos archivos desde el notebook en Google Colab:

   - **OpciÃ³n A**: Subir los archivos directamente al entorno de Colab:
     - Haz clic en el Ã­cono de carpeta (a la izquierda en Colab).
     - Luego haz clic en el Ã­cono de subir archivo (flecha hacia arriba).
     - Carga `train.csv` y `test.csv`.

   - **OpciÃ³n B**: Cargar archivos desde tu Google Drive:
     - Conecta Colab a tu Google Drive al ejecutar este cÃ³digo en una celda:
       ```python
       from google.colab import drive
       drive.mount('/content/drive')
       ```
     - Coloca los archivos en una carpeta de tu Drive (por ejemplo, `/content/drive/MyDrive/bike-sharing/`)
     - Luego carga los datos desde esa ruta en tu notebook.

Ejecuta el notebook (EDA)_Bike_Sharing_Demand.ipynb siguiendo las celdas paso a paso.

#### âš™ï¸ Â¿QuÃ© hace el notebook?

Carga de datos (train.csv, test.csv)

Limpieza y verificaciÃ³n de valores faltantes

AnÃ¡lisis exploratorio con visualizaciones de tendencias

IngenierÃ­a de caracterÃ­sticas:

ExtracciÃ³n de hour, day, month, year desde la columna datetime

ConversiÃ³n de variables si es necesario

Entrenamiento de modelos:

ğŸ² Random Forest 

ğŸ’¡ LightGBM 

âš¡ XGBoost 

EvaluaciÃ³n con la mÃ©trica **RMSLE**

GeneraciÃ³n de archivos de envÃ­o (submission.csv) listos para subir a Kaggle

#### ğŸ“‚ Archivos generados
**submission_rf.csv** â†’ predicciones usando Random Forest

**submission_lgb.csv** â†’ predicciones usando LightGBM

**submission_xgb.csv** â†’ predicciones usando XGBoost

#### ğŸš€ CÃ³mo subir a Kaggle
Ve al apartado "Submit Predictions" del reto:

ğŸ‘‰ [https://www.kaggle.com/competitions/bike-sharing-demand/submit](https://www.kaggle.com/competitions/bike-sharing-demand/overview)

Carga alguno de los archivos .csv generados (por ejemplo, submission_lgb.csv).

Asigna un nombre a tu envÃ­o.

Haz clic en Make Submission.

Kaggle calcularÃ¡ la puntuaciÃ³n basada en la mÃ©trica RMSLE.

---

## âš™ï¸ Fase 2 â€“ Despliegue en contenedor Docker

En esta fase vamos a empaquetar todo el flujo de **entrenamiento** y **predicciÃ³n** en un contenedor Docker, de manera que solo necesites un par de comandos para ejecutar tu modelo en cualquier entorno.

---

### ğŸ–¥ï¸ 0. Prerrequisitos

1. **Instalar Docker Desktop**  
   - Windows Pro/Enterprise/Education: instalaciÃ³n nativa con Hyper-V.  
   - Windows Home: habilita WSL 2 (Windows Subsystem for Linux v2) y marca â€œUse the WSL 2 based engineâ€ en Settings â†’ General.  
   - Linux (Ubuntu, etc.): instala Docker Engine siguiendo la [documentaciÃ³n oficial](https://docs.docker.com/engine/install/).

2. **Arrancar Docker**  
   - En Windows: abre **Docker Desktop** y espera a que el icono de la ballena en la bandeja se ponga verde (â€œDocker is runningâ€).  
   - En Linux: asegÃºrate de que el servicio `docker` estÃ© activo (`systemctl status docker`).

3. **Estructura de carpetas**  
   En la raÃ­z de tu proyecto `Bike-Sharing-Demand/`, crea una carpeta llamada `data/` y coloca dentro:
   
   - **train.csv**: el CSV original de Kaggle con las columnas `datetime,â€¦,count`.  
   - **test.csv**: el CSV de Kaggle que debes predecir (`datetime,â€¦` sin `count`).  
   - **data/** tambiÃ©n recibirÃ¡ `model.pkl`, `scaler.pkl` y `submission.csv` tras la ejecuciÃ³n.

---

### ğŸ³ 1. ConstrucciÃ³n de la imagen Docker

Ejecuta este comando en la carpeta `fase-2/` (donde estÃ¡ tu Dockerfile):

```bash
docker build -t bikeshare .
```

- docker build â†’ construye una nueva imagen Docker.

- -t bikeshare â†’ etiqueta la imagen como bikeshare (nombre fÃ¡cil de recordar).

- . â†’ indica que el contexto (Dockerfile y scripts) estÃ¡ en el directorio actual.

---

### ğŸ§  2. Entrenamiento del modelo

Una vez construida la imagen, monta tu carpeta data/ como volumen en /data dentro del contenedor para entrenar, asÃ­:

En Windows PowerShell
```bash
docker run --rm `
  -v "${PWD}\..\data:/data" `             # Monta Bike-Sharing-Demand/data â‡’ /data
  bikeshare `                             # Usa la imagen bikeshare
  train.py --input_file /data/train.csv ` # Script de entrenamiento
           --model_file /data/model.pkl ` # Guarda modelo entrenado
           --scaler_file /data/scaler.pkl `# Guarda el scaler
           --overwrite_model              # Sobrescribe si ya existe
```
En Linux /bash
```bash
docker run --rm \
  -v "$PWD/../data:/data" \
  bikeshare \
  train.py --input_file  /data/train.csv \
           --model_file  /data/model.pkl \
           --scaler_file /data/scaler.pkl \
           --overwrite_model
```

ExplicaciÃ³n de cada parte:

  - docker run --rm â†’ lanza un contenedor y lo elimina al terminar.
   
  - -v host_path:container_path â†’ monta tu carpeta local data/ en /data dentro del contenedor.
   
  - bikeshare â†’ la imagen que construimos.
   
  - train.py --input_file â€¦ â†’ script que:
   
  - Carga train.csv.
   
  - Extrae hour, day, month, year.
   
  - Elimina outliers y escala con StandardScaler.
   
  - Entrena LGBMRegressor.
   
  - Guarda el modelo y el scaler en /data/model.pkl y /data/scaler.pkl.
   
  - Al terminar verÃ¡s en tu carpeta data/:
   
  - model.pkl â†’ el modelo LightGBM entrenado.
   
  - scaler.pkl â†’ el objeto StandardScaler para procesar test.

---

### ğŸ”® 3. Generar predicciones

Con el modelo y el scaler ya en data/, monta de nuevo y corre:

En Windows PowerShell
```bash
docker run --rm `
  -v "${PWD}\..\data:/data" `
  bikeshare `
  predict.py --input_file       /data/test.csv `   # Test sin etiquetas
             --model_file       /data/model.pkl `  # Modelo entrenado
             --scaler_file      /data/scaler.pkl ` # Mismo scaler usado en train
             --predictions_file /data/submission.csv  # Salida de predicciones
```

En Linux /bash
```bash
docker run --rm \
  -v "$PWD/../data:/data" \
  bikeshare \
  predict.py --input_file       /data/test.csv \
             --model_file       /data/model.pkl \
             --scaler_file      /data/scaler.pkl \
             --predictions_file /data/submission.csv
```
QuÃ© hace predict.py

  - Valida que test.csv, model.pkl y scaler.pkl existan.
   
  - Carga test.csv, convierte datetime, extrae variables temporales.
   
  - Aplica el StandardScaler al set de features.
   
  - Carga el modelo y genera predicciones no negativas.
   
  - Crea submission.csv con columnas:
      ```bash
            datetime,count
      2011-01-20 00:00:00,12
      2011-01-20 01:00:00, 8
      â€¦
      ```
---

### âœ… VerificaciÃ³n

Listado de archivos antes y despuÃ©s de cada paso:

En Windows PowerShell
```bash
docker run --rm `
  -v "${PWD}\..\data:/data" `
  --entrypoint bash `
  bikeshare `
  -c "ls -l /data"
```

En Linux /bash
```bash
docker run --rm -v "$PWD/../data:/data" --entrypoint bash bikeshare \
  -c "ls -l /data"
```

ComprobaciÃ³n de formato de las primeras lÃ­neas:

En Windows PowerShell
```bash
docker run --rm `
  -v "${PWD}\..\data:/data" `
  --entrypoint bash `
  bikeshare `
  -c "head -n 5 /data/submission.csv"
```

En Linux /bash
```bash
docker run --rm -v "$PWD/../data:/data" --entrypoint bash bikeshare \
  -c "head -n 5 /data/submission.csv"
```
ExplicaciÃ³n paso a paso:

  - docker run --rm
   Arranca un contenedor y lo elimina al terminar.
   
  - `-v "${PWD}\..\data:/data"`
   Monta tu carpeta local Bike-Sharing-Demand/data (una carpeta arriba de fase-2) en /data del contenedor.
   
  - `--entrypoint bash`
   Anula el ENTRYPOINT por defecto (python) y usa bash.
   
  - bikeshare
   Nombre de la imagen.
   
  - `-c "ls -l /data"`
   Le dice a bash que ejecute el comando ls -l /data.

---

Con esto tendrÃ¡s un contendor reproducible que:

  - Entrena tu modelo con un solo comando.
   
  - Predice y genera el CSV listo para subir a Kaggle.
   
  - Mantiene tu carpeta data/ como Ãºnico punto de montaje, evitando confusiones con rutas.      
